{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import math"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading dataset and  getting unique affiliations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('papers.csv')\n",
    "unique_affiliations_df = df['Affiliation'].unique()\n",
    "unique_affiliations_df = pd.DataFrame(unique_affiliations_df, columns=['Affiliation'])\n",
    "pd.DataFrame(unique_affiliations_df).to_csv('unique_affiliations.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Getting countries of unique affiliations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using openstreetmap"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "unique_affiliations_df = pd.read_csv('unique_affiliations.csv')\n",
    "unique_affiliations_df['country'] = None\n",
    "\n",
    "none_count = 0\n",
    "\n",
    "for i in tqdm(range(len(unique_affiliations_df))):\n",
    "    try:\n",
    "        institute_name = unique_affiliations_df.loc[i, 'Affiliation']\n",
    "        url = f\"https://nominatim.openstreetmap.org/search?q={institute_name}&format=json&accept-language=en\"\n",
    "\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            results = response.json()\n",
    "            if len(results) > 0:\n",
    "                country = results[0]['display_name'].split(',')[-1].strip()\n",
    "                unique_affiliations_df.loc[i, 'country'] = country\n",
    "            else:\n",
    "                unique_affiliations_df['country'][i] = 'None'\n",
    "                none_count += 1\n",
    "        else:\n",
    "            print(f\"API ERROR\")\n",
    "    except:\n",
    "        print(f\"ERROR: {i}\")\n",
    "        unique_affiliations_df['country'][i] = 'None'\n",
    "        none_count += 1\n",
    "print(f\"None count: {none_count}\")\n",
    "pd.DataFrame(unique_affiliations_df).to_csv('unique_affiliations.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using elsevier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-29T22:47:51.735064Z",
     "end_time": "2023-04-29T22:47:52.286106Z"
    }
   },
   "outputs": [],
   "source": [
    "unique_affiliations_df = pd.read_csv('unique_affiliations.csv')\n",
    "none_df = pd.DataFrame(unique_affiliations_df[unique_affiliations_df['country'] == 'None'].reset_index(drop=True).copy())\n",
    "\n",
    "none_count = 0\n",
    "\n",
    "for i in tqdm(range(len(none_df))):\n",
    "    try:\n",
    "        institute_name = none_df.loc[i, 'Affiliation']\n",
    "\n",
    "        # api_key hidden\n",
    "        api_key = \"***************\"\n",
    "        query = f\"affil({institute_name})\"\n",
    "        url = f\"https://api.elsevier.com/content/search/affiliation?query={query}&apiKey={api_key}\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        data = response.json()\n",
    "        if len(data['search-results']['entry']) > 0:\n",
    "            country = data['search-results']['entry'][0]['country']\n",
    "            none_df.loc[i, 'country'] = country\n",
    "    except:\n",
    "        none_count += 1\n",
    "print(f\"None count: {none_count}\")\n",
    "pd.DataFrame(none_df).to_csv('none_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combining the results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "university_affiliation_df = pd.read_csv('unique_affiliations.csv')\n",
    "none_df = pd.read_csv('none_df.csv')\n",
    "\n",
    "university_affiliation_dict = {}\n",
    "for i in range(len(university_affiliation_df)):\n",
    "    university_affiliation_dict[university_affiliation_df.loc[i, 'Affiliation']] = university_affiliation_df.loc[i, 'country']\n",
    "\n",
    "for i in range(len(none_df)):\n",
    "    university_affiliation_dict[none_df.loc[i, 'Affiliation']] = none_df.loc[i, 'country']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T22:47:55.182040Z",
     "end_time": "2023-04-29T22:47:55.197622Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "papers = pd.read_csv('papers.csv')\n",
    "papers['country'] = None\n",
    "none_count = 0\n",
    "for i in tqdm(range(len(papers))):\n",
    "    institute_name = papers.loc[i, 'Affiliation']\n",
    "    papers.loc[i, 'country'] = university_affiliation_dict[institute_name]\n",
    "\n",
    "#save papers_with_country\n",
    "papers.to_csv('papers_with_country.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-29T18:27:50.923447Z",
     "end_time": "2023-04-29T20:32:29.872670Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using openstreetmap and elsevier, we were able to get the country of 93% of the contributions. The remaining 7% of the papers were not able to be found in the databases. We will be using the papers_with_country.csv for the rest of the analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Number of contributions of each country from 2006 to 2021"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Exporting the total contribution of each country from 2006 to 2021 to a csv file. Also exporting the log of the contribution of each country for each year from 2006 to 2021 to a csv file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Export the country count\n",
    "papers['country'].value_counts().to_csv('country_count.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T00:42:33.606195Z",
     "end_time": "2023-04-30T00:42:35.033896Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The below code reads a dataset of papers with country information, calculates the number of contributions done by the top 15 countries for each year, and saves the results in two separate CSV files, one with the raw data and another with the logarithmic transformation of the data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read papers_with_country\n",
    "papers = pd.read_csv('papers_with_country.csv')\n",
    "years = papers['Year'].unique()\n",
    "#top 15 countries\n",
    "top_15 = dict(papers['country'].value_counts()[:16])\n",
    "#delete none\n",
    "del top_15['None']\n",
    "df_country_year = pd.DataFrame(columns=['country']+list(years))\n",
    "#fill df_country_year\n",
    "for country in top_15.keys():\n",
    "    df_country_year.loc[len(df_country_year)] = [country]+[0]*len(years)\n",
    "    for year in years:\n",
    "        df_country_year.loc[df_country_year['country'] == country, year] = len(papers[(papers['country'] == country) & (papers['Year'] == year)])\n",
    "df_country_year.to_csv('country_year_contributions.csv')\n",
    "\n",
    "#also save log data\n",
    "df_country_year_log = df_country_year.copy()\n",
    "for year in years:\n",
    "    df_country_year_log[year] = df_country_year_log[year].apply(lambda x: 0 if x == 0 else math.log(x))\n",
    "df_country_year_log.to_csv('country_year_contributions_log.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T02:34:43.904688Z",
     "end_time": "2023-04-30T02:34:44.532468Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://datawrapper.dwcdn.net/YX27D/1/\n",
    "https://datawrapper.dwcdn.net/E4Qdp/1/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Rate of change of contribution of each country from 2006 to 2021"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The below code calculates the slope of the number of papers published by each country for each year, adjusts the values by adding the absolute value of the minimum slope, takes the logarithm of the adjusted values, and saves the results in a CSV file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_country_year = pd.read_csv('country_year_contributions.csv')\n",
    "\n",
    "columns = df_country_year.columns[1:]\n",
    "df_country_year_slope = pd.DataFrame(columns=list(columns[:-1]))\n",
    "\n",
    "minn_slope = 100000\n",
    "for i in range(len(df_country_year)):\n",
    "    country = df_country_year.loc[i, 'country']\n",
    "    df_country_year_slope.loc[len(df_country_year_slope)] = [country]+[0]*(len(df_country_year_slope.columns)-1)\n",
    "    for j in range(1,len(columns)-1):\n",
    "        slope = df_country_year.loc[i, columns[j+1]] - df_country_year.loc[i, columns[j]]\n",
    "        df_country_year_slope.loc[df_country_year_slope['country'] == country, columns[j+1]] = slope\n",
    "        if slope < minn_slope:\n",
    "            minn_slope = slope\n",
    "\n",
    "#add minn_slope to all values\n",
    "for i in range(len(df_country_year_slope)):\n",
    "    for j in range(1,len(columns)):\n",
    "        df_country_year_slope.loc[i, columns[j]] += abs(minn_slope)\n",
    "\n",
    "for year in df_country_year_slope.columns[1:]:\n",
    "    df_country_year_slope[year] = df_country_year_slope[year].apply(lambda x: 0 if x == 0 else math.log(x))\n",
    "\n",
    "df_country_year_slope.to_csv('country_year_contributions_slope.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T03:29:53.739631Z",
     "end_time": "2023-04-30T03:29:53.800665Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Datawrapper website is used for creating the following chart.\n",
    "The chart indicates that before 2015, most countries experienced a constant rate of growth in contributions, with the United States and United Kingdom having higher growth rates than the others. However, after 2021, the number of contributions decreased, resulting in lower growth rates for all countries. India had a constant growth rate till 2020, but it experienced a decrease in the number of contributions in 2021. In terms of AI development breakthroughs, it's worth noting that 2015 was a significant year for the field of artificial intelligence. This was the year when DeepMind's AlphaGo defeated Lee Sedol, a world champion in the ancient board game of Go."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://datawrapper.dwcdn.net/GHIt6/1/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<iframe title=\"Rate of increase of contributions in logarithmic scale\" aria-label=\"Interactive line chart\" id=\"datawrapper-chart-GHIt6\" src=\"https://datawrapper.dwcdn.net/GHIt6/1/\" scrolling=\"no\" frameborder=\"0\" style=\"width: 0; min-width: 100% !important; border: none;\" height=\"400\" data-external=\"1\"></iframe><script type=\"text/javascript\">!function(){\"use strict\";window.addEventListener(\"message\",(function(a){if(void 0!==a.data[\"datawrapper-height\"]){var e=document.querySelectorAll(\"iframe\");for(var t in a.data[\"datawrapper-height\"])for(var r=0;r<e.length;r++)if(e[r].contentWindow===a.source){var i=a.data[\"datawrapper-height\"][t]+\"px\";e[r].style.height=i}}}))}();</script>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
